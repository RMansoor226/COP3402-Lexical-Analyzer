My prompt: case ',':
                tokens[t] = commasym;
                strcpy(lexemes[t], ",");
                t++;
                break;
            case ';':
                tokens[t] = semicolonsym;
                strcpy(lexemes[t], ";");
                t++;
                break;
            case '.':
                tokens[t] = periodsym;
                strcpy(lexemes[t], ".");
                t++;
                break; I have a problem with this code, for the ";" case and the "." case, it is printing an unecessary extra blank line below it. The comma doesn't have that issue. Is there any difference in the code?
ChatGPT said:

Looking at the three case blocks you posted:

case ',':
    tokens[t] = commasym;
    strcpy(lexemes[t], ",");
    t++;
    break;

case ';':
    tokens[t] = semicolonsym;
    strcpy(lexemes[t], ";");
    t++;
    break;

case '.':
    tokens[t] = periodsym;
    strcpy(lexemes[t], ".");
    t++;
    break;


There‚Äôs no functional difference between them ‚Äî all three do the same thing (assign a token, copy a string, increment t). So the extra blank line you‚Äôre seeing when printing cannot be caused by the switch snippet itself.

The difference is likely happening in your printing logic, not in tokenization. A few common culprits:

Newline in lexeme array
When you later printf("%s\n", lexemes[i]);, if lexemes[i] accidentally has a newline "\n" inside it, you‚Äôll get two newlines.

For example: if lexemes[i] is actually ";\n\0" instead of ";\0".

That would print ; followed by a newline from the string itself, plus another newline from your printf.

Memory overwrite
If lexemes[t] wasn‚Äôt properly zeroed or allocated with enough space, strcpy could be leaving junk characters (like '\n') after the ; or ..

Different print format
Maybe in your loop you do something like:

printf("%s\n", lexemes[i]);  // always adds a newline


If lexemes[i] already contains a trailing newline, you‚Äôd see an extra blank line.

‚úÖ How to test quickly
Instead of printf("%s\n", lexemes[i]);, try:

printf("[%s]\n", lexemes[i]);


If you see "[;]" but still get a blank line, then the extra newline is coming from your printf.
If you see "[; ]" or "[;\n]", then you know your string actually contains an embedded newline.

üëâ My guess: your lexemes[t] for ; and . somehow have a newline character inside (probably from how you‚Äôre reading the input before the switch).

Do you want me to help you trace exactly how those characters are read into your lexer?

You said:
both semicolon and begin have a [ under them now
ChatGPT said:

Got it üëç ‚Äî so when you switched to

printf("[%s]\n", lexemes[i]);


you saw:

[,]
[;]
[begin]


but under ; and begin you‚Äôre also seeing another [ on a separate blank line. That means the string for ; and begin actually contains an extra newline character inside the lexeme, so it prints once for ; (or begin), then immediately starts a new line before printing the ].

Why this happens

When you read characters from the source, you‚Äôre probably pulling them in with something like fgetc, fgets, or scanf("%s", ...).

fgets in particular keeps the newline ('\n') if there‚Äôs room in the buffer.

So if you copied that into lexemes[t], it would store ";\n\0" instead of just ";\0".

That‚Äôs why printf("[%s]\n", lexemes[i]); shows:

[;         <--- semicolon
]          <--- newline inside string forced the closing bracket to print on the next line

How to fix it

Before you use or store the string, strip out the newline. Common ways:

1. Manually trim after reading:

// after fgets or similar
lexemes[t][strcspn(lexemes[t], "\n")] = '\0';


2. If you‚Äôre building lexemes char by char:
Make sure you never copy '\n' into them ‚Äî skip over whitespace when tokenizing.

Quick test

Print the raw characters one by one to confirm:

for (int j = 0; lexemes[i][j] != '\0'; j++) {
    printf("%d ", lexemes[i][j]);
}
printf("\n");


If you see 59 10 for semicolon (ASCII 59 = ;, ASCII 10 = newline), that‚Äôs the culprit.

üëâ Do you want me to help you patch the part of your lexer that builds lexemes[t] so it strips out newlines before storing?

You said:
#include <stdio.h>
#include <string.h>
#include <ctype.h>

typedef enum {
    skipsym = 1 , // Skip / ignore token
    identsym , // Identifier
    numbersym , // Number
    plussym , // +
    minussym , // -
    multsym , // *
    slashsym , // /
    eqsym , // =
    neqsym , // <>
    lessym , // <
    leqsym , // <=
    gtrsym , // >
    geqsym , // >=
    lparentsym , // (
    rparentsym , // )
    commasym , // ,
    semicolonsym , // ;
    periodsym , // .
    becomessym , // :=
    beginsym , // begin
    endsym , // end
    ifsym , // if
    fisym , // fi
    thensym , // then
    whilesym , // while
    dosym , // do
    callsym , // call
    constsym , // const
    varsym , // var
    procsym , // procedure
    writesym , // write
    readsym , // read
    elsesym , // else
    evensym // even
} TokenType ;

int main(int argc, char* argv[]) {
    /*
    Pseudocode for Lexical Analyzer
    Step 1. Initialize keywords, operators, and delimiters
    Step 2. Read the source code file
        a. Skip comments
            i. Skip single-line comments (//)
            ii. Skip multi-line comments (/*)
        b. Skip whitespace
            i. Spaces
            ii. Tabs
            iii. Newlines
    Step 3. Tokenize the source code's keywords, operators, and delimiters
    Step 4. Identify and classify tokens
    Step 5. Handle errors
        a. Identifier too long (> 11 chars) Error
        b. Number too long (> 5 digits) Error
        c. Invalid Symbol Error
    Step 6. Output the tokens
        Step 6.1. Print Lexeme Table to console
        Step 6.2. Print Token List to console
    Step 7. Terminate
    */
    FILE *inputFile = fopen(argv[1], "r");

    // Check if input file opened successfully
    if (!inputFile) {
        printf("Error opening file.\n");
        return 1;
    }

    char info[100];
    int i = 0;
    int j = 0;

    // Print header

    printf("Source Program:\n");

    // Print input file contents
    while (fgets(info, sizeof(info), inputFile)) {
        printf("%s", info);
    }

    fseek(inputFile, 0, SEEK_SET);

    // Print Lexeme Table header

    printf("\nLexeme Table:\n");
    printf("\nlexeme\ttoken type\n");

    // Scan input file character by character excluding whitespace
    while ((j = fgetc(inputFile)) != EOF && i < sizeof(info) - 1) {
        if ((char) j == ' ' || (char) j == '\t' || (char) j == '\n' || (char) j == '\0') {
            continue; // Skip whitespace
            i++;
        }
        info[i++] = (char) j;
    }

    info[i] = '\0'; // Null-terminate the string

    char lexemes[100][20]; // Assuming max 100 lexemes, each up to 19 chars + null terminator
    char tokens[100];
    int t = 0;
    for (int k=0; k<i; k++) {
        switch (info[k]) {
            case '+':
                tokens[t] = plussym;
                strcpy(lexemes[t], "+");
                t++;
                break;
            case '-':
                tokens[t] = minussym;
                strcpy(lexemes[t], "-");
                t++;
                break;
            case '*':
                tokens[t] = multsym;
                strcpy(lexemes[t], "*");
                t++;
                break;
            case '/':
                tokens[t] = slashsym;
                strcpy(lexemes[t], "/");
                t++;
                break;
            case '=':
                tokens[t] = eqsym;
                strcpy(lexemes[t], "=");
                t++;
                break;
            case '<':
                switch (info[k+1]) {
                    case '=':
                        tokens[t] = leqsym;
                        strcpy(lexemes[t], "<=");
                        t++;
                        k++; // Skip the next character as it's part of the token
                        break;
                    case '>':
                        tokens[t] = neqsym;
                        strcpy(lexemes[t], "<>");
                        t++;
                        k++; // Skip the next character as it's part of the token
                        break;
                    default:
                        tokens[t] = lessym;
                        strcpy(lexemes[t], "<");
                        t++;
                        break;
                }
                break;
            case '>':
                if (info[k+1] == '=') {
                    tokens[t] = geqsym;
                    strcpy(lexemes[t], ">=");
                    t++;
                    k++; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = gtrsym;
                    strcpy(lexemes[t], ">");
                    t++;
                }
                break;
            case '(':
                tokens[t] = lparentsym;
                strcpy(lexemes[t], "(");
                t++;
                break;
            case ')':
                tokens[t] = rparentsym;
                strcpy(lexemes[t], ")");
                t++;
                break;
            case ',':
                tokens[t] = commasym;
                strcpy(lexemes[t], ",");
                t++;
                break;
            case ';':
                tokens[t] = semicolonsym;
                strcpy(lexemes[t], ";");
                t++;
                break;
            case '.':
                tokens[t] = periodsym;
                strcpy(lexemes[t], ".");
                t++;
                break;
            case ':':
                if (info[k+1] == '=') {
                    tokens[t] = becomessym;
                    strcpy(lexemes[t], ":=");
                    t++;
                    k++; // Skip the next character as it's part of the token
                } else {
                    printf("Error: Invalid symbol ':'\n");
                    strcpy(lexemes[t], ":");
                }
                break;
            case 'b':
                if (info[k+1] == 'e' && info[k+2] == 'g' && info[k+3] == 'i' && info[k+4] == 'n') {
                    tokens[t] = beginsym;
                    strcpy(lexemes[t], "begin");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "b");
                    t++;
                }
                break;
            case 'e':
                if (info[k+1] == 'n' && info[k+2] == 'd') {
                    tokens[t] = endsym;
                    strcpy(lexemes[t], "end");
                    t++;
                    k += 2; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'l' && info[k+2] == 's' && info[k+3] == 'e') {
                    tokens[t] = elsesym;
                    strcpy(lexemes[t], "else");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'v' && info[k+2] == 'e' && info[k+3] == 'n') {
                    tokens[t] = evensym;
                    strcpy(lexemes[t], "even");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "e");
                    t++;
                }
                break;
            case 'i':
                if (info[k+1] == 'f') {
                    tokens[t] = ifsym;
                    strcpy(lexemes[t], "if");
                    t++;
                    k += 1; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "i");
                    t++;
                }
                break;
            case 'f':
                if (info[k+1] == 'i') {
                    tokens[t] = fisym;
                    strcpy(lexemes[t], "fi");
                    t++;
                    k += 1; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "f");
                    t++;
                }
                break;
            case 't':
                if (info[k+1] == 'h' && info[k+2] == 'e' && info[k+3] == 'n') {
                    tokens[t] = thensym;
                    strcpy(lexemes[t], "then");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "t");
                    t++;
                }
                break;
            case 'w':
                if (info[k+1] == 'h' && info[k+2] == 'i' && info[k+3] == 'l' && info[k+4] == 'e') {
                    tokens[t] = whilesym;
                    strcpy(lexemes[t], "while");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'r' && info[k+2] == 'i' && info[k+3] == 't' && info[k+4] == 'e') {
                    tokens[t] = writesym;
                    strcpy(lexemes[t], "write");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "w");
                    t++;
                }
                break;
            case 'd':
                if (info[k+1] == 'o') {
                    tokens[t] = dosym;
                    strcpy(lexemes[t], "do");
                    t++;
                    k += 1; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "d");
                    t++;
                }
                break;
            case 'c':
                if (info[k+1] == 'a' && info[k+2] == 'l' && info[k+3] == 'l') {
                    tokens[t] = callsym;
                    strcpy(lexemes[t], "call");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'o' && info[k+2] == 'n' && info[k+3] == 's' && info[k+4] == 't') {
                    tokens[t] = constsym;
                    strcpy(lexemes[t], "const");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "c");
                    t++;
                }
                break;
            case 'v':
                if (info[k+1] == 'a' && info[k+2] == 'r') {
                    tokens[t] = varsym;
                    strcpy(lexemes[t], "var");
                    t++;
                    k += 2; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "v");
                    t++;
                }
                break;
            case 'p':
                if (info[k+1] == 'r' && info[k+2] == 'o' && info[k+3] == 'c' && info[k+4] == 'e' && info[k+5] == 'd' && info[k+6] == 'u' && info[k+7] == 'r' && info[k+8] == 'e') {
                    tokens[t] = procsym;
                    strcpy(lexemes[t], "procedure");
                    t++;
                    k += 8; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "p");
                    t++;
                }
                break;
            case 'r':
                if (info[k+1] == 'e' && info[k+2] == 'a' && info[k+3] == 'd') {
                    tokens[t] = readsym;
                    strcpy(lexemes[t], "read");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "r");
                    t++;
                }
                break;
            default:
                if (isdigit(info[k])) {
                    int start = k;
                    int len = 0;
                    while (isdigit(info[k]) && len < 6) { // Max 5 digits
                        strncat(lexemes[t], &info[k], 1);
                        k++;
                        len++;
                    }
                    strncpy(lexemes[t], &info[start], len);
                    lexemes[t][len] = '\0'; // Null-terminate the string
                    if (len > 5) {
                        tokens[t] = skipsym;
                        t++;
                    }   else {
                        tokens[t] = numbersym;
                        t++;
                    }
                    k--; // Adjust for the outer loop increment
                } else if (isalpha(info[k])) {
                    int start = k;
                    int len = 1;
//                    while (isalnum(info[k])) { // Accept letters and digits
//                        strncat(lexemes[t], &info[k], 1);
//                        k++;
//                        len++;
//                    }
                    strncpy(lexemes[t], &info[start], len);
                    lexemes[t][len] = '\0'; // Null-terminate the string
                    tokens[t] = identsym;
                    t++;
                } else {
                    strcpy(lexemes[t], &info[k]);
                    lexemes[t][1] = '\0';
                    tokens[t] = skipsym;
                    t++;
                }
                break;
        }
        printf("%s %8d\n", lexemes[t-1], tokens[t-1]);
    }

    printf("\nToken List:\n\n");

    for (int l = 0; l < t; l++) {
        printf("%d ", tokens[l]);
        if (tokens[l] == 2 || tokens[l] == 3) {
            printf("%s ", lexemes[l]);
        }
    }

    fclose(inputFile);

    return 0;
} the problem is with the begin and ; cases, every other case prints fine
ChatGPT said:

Thanks for pasting the full code ‚Äî that makes the issue much clearer üëå

The problem isn‚Äôt actually in the ; case or the begin case themselves (they‚Äôre coded fine). The extra blank line you see when printing is because of how you‚Äôre filling info[] and then how you print lexemes.

Let‚Äôs walk through it carefully:

üîé Where the bug comes from

In your scanner loop:

while ((j = fgetc(inputFile)) != EOF && i < sizeof(info) - 1) {
    if ((char) j == ' ' || (char) j == '\t' || (char) j == '\n' || (char) j == '\0') {
        continue; // Skip whitespace
        i++;
    }
    info[i++] = (char) j;
}


Notice two problems:

That i++ after continue never executes because it‚Äôs after continue.
‚Üí So your indexing isn‚Äôt lining up correctly. Sometimes you overwrite previous characters with \n or stray data.

fgets at the beginning already left newline characters \n in your info buffer when you first printed the source. Since you didn‚Äôt filter them all out properly, those newlines sneak into info[].

So when you hit "begin" or ";", you‚Äôre sometimes actually storing:

"begin\n"
";\n"


instead of just "begin" and ";". That‚Äôs why the debug print with [%s] showed the bracket on the next line.

‚úÖ Fix

Move i++ outside of the continue block and make sure you don‚Äôt copy whitespace:

while ((j = fgetc(inputFile)) != EOF && i < sizeof(info) - 1) {
    if ((char) j == ' ' || (char) j == '\t' || (char) j == '\n')
        continue; // Skip whitespace completely

    info[i++] = (char) j;
}
info[i] = '\0';


That way, info[] contains only meaningful characters (no stray newlines).

üõ†Ô∏è Extra debugging tip

To prove it‚Äôs newlines in your lexemes, print their ASCII values:

printf("%s %8d  [", lexemes[t-1], tokens[t-1]);
for (int z = 0; lexemes[t-1][z] != '\0'; z++) {
    printf("%d ", (unsigned char)lexemes[t-1][z]);
}
printf("]\n");


If you see 59 10 ‚Üí that‚Äôs ; (ASCII 59) followed by \n (ASCII 10).
If you see 98 101 103 105 110 10 ‚Üí that‚Äôs "begin\n".

üëâ Do you want me to patch your code fully so begin, ;, and all keywords/tokens are guaranteed not to carry extra \n characters?

You said:
#include <stdio.h>
#include <string.h>
#include <ctype.h>

typedef enum {
    skipsym = 1 , // Skip / ignore token
    identsym , // Identifier
    numbersym , // Number
    plussym , // +
    minussym , // -
    multsym , // *
    slashsym , // /
    eqsym , // =
    neqsym , // <>
    lessym , // <
    leqsym , // <=
    gtrsym , // >
    geqsym , // >=
    lparentsym , // (
    rparentsym , // )
    commasym , // ,
    semicolonsym , // ;
    periodsym , // .
    becomessym , // :=
    beginsym , // begin
    endsym , // end
    ifsym , // if
    fisym , // fi
    thensym , // then
    whilesym , // while
    dosym , // do
    callsym , // call
    constsym , // const
    varsym , // var
    procsym , // procedure
    writesym , // write
    readsym , // read
    elsesym , // else
    evensym // even
} TokenType ;

int main(int argc, char* argv[]) {
    /*
    Pseudocode for Lexical Analyzer
    Step 1. Initialize keywords, operators, and delimiters
    Step 2. Read the source code file
        a. Skip comments
            i. Skip single-line comments (//)
            ii. Skip multi-line comments (/*)
        b. Skip whitespace
            i. Spaces
            ii. Tabs
            iii. Newlines
    Step 3. Tokenize the source code's keywords, operators, and delimiters
    Step 4. Identify and classify tokens
    Step 5. Handle errors
        a. Identifier too long (> 11 chars) Error
        b. Number too long (> 5 digits) Error
        c. Invalid Symbol Error
    Step 6. Output the tokens
        Step 6.1. Print Lexeme Table to console
        Step 6.2. Print Token List to console
    Step 7. Terminate
    */
    FILE *inputFile = fopen(argv[1], "r");

    // Check if input file opened successfully
    if (!inputFile) {
        printf("Error opening file.\n");
        return 1;
    }

    char info[100];
    int i = 0;
    int j = 0;

    // Print header

    printf("Source Program:\n");

    // Print input file contents
    while (fgets(info, sizeof(info), inputFile)) {
        printf("%s", info);
    }

    fseek(inputFile, 0, SEEK_SET);

    // Print Lexeme Table header

    printf("\nLexeme Table:\n");
    printf("\nlexeme\ttoken type\n");

    // Scan input file character by character excluding whitespace
    while ((j = fgetc(inputFile)) != EOF && i < sizeof(info) - 1) {
        if ((char) j == ' ' || (char) j == '\t' || (char) j == '\n') {
            continue; // Skip whitespace
            
        }
        info[i++] = (char) j;
    }

    info[i] = '\0'; // Null-terminate the string
    
    char lexemes[100][20]; // Assuming max 100 lexemes, each up to 19 chars + null terminator
    char tokens[100];
    int t = 0;
    char message[20];
    for (int k=0; k<i; k++) {
        switch (info[k]) {
            case '+':
                tokens[t] = plussym;
                strcpy(lexemes[t], "+");
                t++;
                break;
            case '-':
                tokens[t] = minussym;
                strcpy(lexemes[t], "-");
                t++;
                break;
            case '*':
                tokens[t] = multsym;
                strcpy(lexemes[t], "*");
                t++;
                break;
            case '/':
                tokens[t] = slashsym;
                strcpy(lexemes[t], "/");
                t++;
                break;
            case '<':
                switch (info[k+1]) {
                    case '=':
                        tokens[t] = leqsym;
                        strcpy(lexemes[t], "<=");
                        t++;
                        k++; // Skip the next character as it's part of the token
                        break;
                    case '>':
                        tokens[t] = neqsym;
                        strcpy(lexemes[t], "<>");
                        t++;
                        k++; // Skip the next character as it's part of the token
                        break;
                    default:
                        tokens[t] = lessym;
                        strcpy(lexemes[t], "<");
                        t++;
                        break;
                }
                break;
            case '>':
                if (info[k+1] == '=') {
                    tokens[t] = geqsym;
                    strcpy(lexemes[t], ">=");
                    t++;
                    k++; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = gtrsym;
                    strcpy(lexemes[t], ">");
                    t++;
                }
                break;
            case '(':
                tokens[t] = lparentsym;
                strcpy(lexemes[t], "(");
                t++;
                break;
            case ')':
                tokens[t] = rparentsym;
                strcpy(lexemes[t], ")");
                t++;
                break;
            case ',':
                tokens[t] = commasym;
                strcpy(lexemes[t], ",");
                t++;
                break;
            case ';':
                tokens[t] = semicolonsym;
                strcpy(lexemes[t], ";");
                t++;
                break;
            case '.':
                tokens[t] = periodsym;
                strcpy(lexemes[t], ".");
                t++;
                break;
            case ':':
                if (info[k+1] == '=') {
                    tokens[t] = becomessym;
                    strcpy(lexemes[t], ":=");
                    t++;
                    k++; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = skipsym;
                    strcpy(lexemes[t], ":");
                    strcpy(message, "Invalid symbol");
                    t++;

                }
                break;
            case '=':
                tokens[t] = eqsym;
                strcpy(lexemes[t], "=");
                t++;
                break;
            case 'b':
                if (info[k+1] == 'e' && info[k+2] == 'g' && info[k+3] == 'i' && info[k+4] == 'n') {
                    tokens[t] = beginsym;
                    strcpy(lexemes[t], "begin");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "b");
                    t++;
                }
                break;
            case 'e':
                if (info[k+1] == 'n' && info[k+2] == 'd') {
                    tokens[t] = endsym;
                    strcpy(lexemes[t], "end");
                    t++;
                    k += 2; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'l' && info[k+2] == 's' && info[k+3] == 'e') {
                    tokens[t] = elsesym;
                    strcpy(lexemes[t], "else");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'v' && info[k+2] == 'e' && info[k+3] == 'n') {
                    tokens[t] = evensym;
                    strcpy(lexemes[t], "even");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "e");
                    t++;
                }
                break;
            case 'i':
                if (info[k+1] == 'f') {
                    tokens[t] = ifsym;
                    strcpy(lexemes[t], "if");
                    t++;
                    k += 1; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "i");
                    t++;
                }
                break;
            case 'f':
                if (info[k+1] == 'i') {
                    tokens[t] = fisym;
                    strcpy(lexemes[t], "fi");
                    t++;
                    k += 1; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "f");
                    t++;
                }
                break;
            case 't':
                if (info[k+1] == 'h' && info[k+2] == 'e' && info[k+3] == 'n') {
                    tokens[t] = thensym;
                    strcpy(lexemes[t], "then");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "t");
                    t++;
                }
                break;
            case 'w':
                if (info[k+1] == 'h' && info[k+2] == 'i' && info[k+3] == 'l' && info[k+4] == 'e') {
                    tokens[t] = whilesym;
                    strcpy(lexemes[t], "while");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'r' && info[k+2] == 'i' && info[k+3] == 't' && info[k+4] == 'e') {
                    tokens[t] = writesym;
                    strcpy(lexemes[t], "write");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "w");
                    t++;
                }
                break;
            case 'd':
                if (info[k+1] == 'o') {
                    tokens[t] = dosym;
                    strcpy(lexemes[t], "do");
                    t++;
                    k += 1; // Skip the next character as it's part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "d");
                    t++;
                }
                break;
            case 'c':
                if (info[k+1] == 'a' && info[k+2] == 'l' && info[k+3] == 'l') {
                    tokens[t] = callsym;
                    strcpy(lexemes[t], "call");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else if (info[k+1] == 'o' && info[k+2] == 'n' && info[k+3] == 's' && info[k+4] == 't') {
                    tokens[t] = constsym;
                    strcpy(lexemes[t], "const");
                    t++;
                    k += 4; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "c");
                    t++;
                }
                break;
            case 'v':
                if (info[k+1] == 'a' && info[k+2] == 'r') {
                    tokens[t] = varsym;
                    strcpy(lexemes[t], "var");
                    t++;
                    k += 2; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "v");
                    t++;
                }
                break;
            case 'p':
                if (info[k+1] == 'r' && info[k+2] == 'o' && info[k+3] == 'c' && info[k+4] == 'e' && info[k+5] == 'd' && info[k+6] == 'u' && info[k+7] == 'r' && info[k+8] == 'e') {
                    tokens[t] = procsym;
                    strcpy(lexemes[t], "procedure");
                    t++;
                    k += 8; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "p");
                    t++;
                }
                break;
            case 'r':
                if (info[k+1] == 'e' && info[k+2] == 'a' && info[k+3] == 'd') {
                    tokens[t] = readsym;
                    strcpy(lexemes[t], "read");
                    t++;
                    k += 3; // Skip the next characters as they're part of the token
                } else {
                    tokens[t] = identsym; // Assume it's an identifier
                    strcpy(lexemes[t], "r");
                    t++;
                }
                break;
            default:
                if (isdigit(info[k])) {
                    int start = k;
                    int len = 0;
                    while (isdigit(info[k]) && len < 6) { // Max 5 digits
                        strncat(lexemes[t], &info[k], 1);
                        k++;
                        len++;
                    }
                    strncpy(lexemes[t], &info[start], len);
                    lexemes[t][len] = '\0'; // Null-terminate the string
                    if (len > 5) {
                        strcpy(message, "Number too long");
                        tokens[t] = skipsym;
                        t++;
                    }   else {
                        tokens[t] = numbersym;
                        t++;
                    }
                    k--; // Adjust for the outer loop increment
                } else if (isalpha(info[k])) {
                    int start = k;
                    int len = 0;
                    while (isalnum(info[k]) && len < 12) { // Max 5 digits
                        strncat(lexemes[t], &info[k], len);
                        k++;
                        len++;
                    }
                    strncpy(lexemes[t], &info[start], len);
                    lexemes[t][len] = '\0'; // Null-terminate the string
                    if (len > 11) {
                        strcpy(message, "Identifier too long");
                        tokens[t] = skipsym;
                        t++;
                    }   else {
                        tokens[t] = identsym;
                        t++;
                    }
                } else {
                    strcpy(lexemes[t], &info[k]);
                    strcpy(message, "Invalid symbols");
                    lexemes[t][1] = '\0';
                    tokens[t] = skipsym;
                    t++;
                }
                break;
        }
        
        if (tokens[t-1] == skipsym) {
            printf("%-7s %-10s\n", lexemes[t-1], message);
        } else {
            // Print lexeme and token type
            printf("%-7s %-10d\n", lexemes[t-1], tokens[t-1]);
        }
    }
    
    printf("\nToken List:\n\n");

    for (int l = 0; l < t; l++) {
        printf("%d ", tokens[l]);
        if (tokens[l] == 2 || tokens[l] == 3) {
            printf("%s ", lexemes[l]);
        }
    }

    fclose(inputFile);

    return 0;
} I have this code now, and there's a few problems. For starters, the comma and semicolon arent being read at all. And theres still whitespace being read as an invalid symbol. Is there any way I can fix it?
ChatGPT said:

Got it üëç thanks for posting the full code.

I can see two root issues with your current scanner:

Whitespace is still getting stored in info[] and treated as tokens later

Your comma (',') and semicolon (';') cases are fine in the switch, but they aren‚Äôt being reached because of how you‚Äôre filling info[].

Let me break it down.

Problem 1: Whitespace still sneaks in

Right now you have:

while ((j = fgetc(inputFile)) != EOF && i < sizeof(info) - 1) {
    if ((char) j == ' ' || (char) j == '\t' || (char) j == '\n') {
        continue; // Skip whitespace
    }
    info[i++] = (char) j;
}


That looks correct, but notice what happens:

continue; skips storing the whitespace but does not increment i, which is fine.

Later, when you tokenize, you have cases like default: which do:

strcpy(lexemes[t], &info[k]);
lexemes[t][1] = '\0';
tokens[t] = skipsym;
t++;


That strcpy(lexemes[t], &info[k]); is dangerous. It copies everything from info[k] onward until a null terminator. If info[k] was skipped whitespace or an unexpected character, you get junk tokens.

‚úÖ Fix:
Instead of copying whole tails of strings, only copy the single character:

lexemes[t][0] = info[k];
lexemes[t][1] = '\0';


That way, you don‚Äôt accidentally slurp whitespace or multiple characters.

Problem 2: Comma and semicolon not recognized

Your switch has:

case ',':
    tokens[t] = commasym;
    strcpy(lexemes[t], ",");
    t++;
    break;
case ';':
    tokens[t] = semicolonsym;
    strcpy(lexemes[t], ";");
    t++;
    break;


That‚Äôs perfect.
The issue is that in your later default: block, you sometimes advance k incorrectly (e.g., inside identifier/number loops). That can cause the parser to skip over commas and semicolons in info[].

‚úÖ Fix:

Make sure identifier and number loops stop before punctuation.

Right now, this part is wrong:

while (isalnum(info[k]) && len < 12) { 
    strncat(lexemes[t], &info[k], len);
    k++;
    len++;
}


üëâ strncat(..., len) is incorrect ‚Äî it appends len characters, not one. You should just append 1 character:

while (isalnum(info[k]) && len < 11) { 
    lexemes[t][len++] = info[k++];
}
lexemes[t][len] = '\0';


This ensures identifiers don‚Äôt ‚Äúeat‚Äù commas, semicolons, or periods that follow them.

Minimal changes you should make

Fix default: invalid symbol handling:

lexemes[t][0] = info[k];
lexemes[t][1] = '\0';
tokens[t] = skipsym;
t++;


Fix identifier building loop:

else if (isalpha(info[k])) {
    int start = k;
    int len = 0;
    while (isalnum(info[k]) && len < 11) {
        lexemes[t][len++] = info[k++];
    }
    lexemes[t][len] = '\0';
    if (len > 11) {
        strcpy(message, "Identifier too long");
        tokens[t] = skipsym;
    } else {
        tokens[t] = identsym;
    }
    t++;
    k--; // adjust because outer loop will increment k
}


Do the same fix for number-building loop.

‚úÖ End result

After these fixes:

Whitespace won‚Äôt appear as "invalid symbols."

Comma , and semicolon ; will be tokenized normally.

Identifiers and numbers won‚Äôt swallow punctuation.

Do you want me to patch your code directly with these fixes so you can test it right away, or do you prefer I just point out the lines to replace?

You said:
the commas and semicolons are being read properly, but now the spacing issue is even wierder. Now weird characters are being displayed on top of the empty space
ChatGPT said:

Ah ‚Äî I see what‚Äôs happening. The ‚Äúweird characters‚Äù showing up in place of spaces are most likely caused by two things in your current code:

Uninitialized arrays
In char lexemes[100][20];, each lexemes[t] slot is not cleared before you start strcpy/strncat into it. That means leftover garbage from memory is getting printed.

Using strncat incorrectly
When building identifiers/numbers, you‚Äôre doing strncat(lexemes[t], &info[k], len); where len isn‚Äôt the right parameter. strncat expects the number of characters to copy, but you‚Äôre passing len (which grows with the loop). That appends more than intended and corrupts the string.

üîß Fix

Here‚Äôs how to clean it up:

(a) Zero‚Äêinitialize each lexeme slot before writing to it
memset(lexemes[t], 0, sizeof(lexemes[t]));


Do this before you strcpy/strncat into lexemes[t].

(b) Don‚Äôt use strncat in that loop

Instead, just copy one character at a time:

int start = k;
int len = 0;
while (isdigit(info[k]) && len < 5) {
    lexemes[t][len++] = info[k++];
}
lexemes[t][len] = '\0'; // terminate


Do the same for identifiers:

int start = k;
int len = 0;
while (isalnum(info[k]) && len < 11) {
    lexemes[t][len++] = info[k++];
}
lexemes[t][len] = '\0';


This way, you don‚Äôt accidentally grab whitespace or random memory.

‚úÖ Corrected snippet for numbers
if (isdigit(info[k])) {
    int len = 0;
    memset(lexemes[t], 0, sizeof(lexemes[t]));
    while (isdigit(info[k]) && len < 5) {
        lexemes[t][len++] = info[k++];
    }
    lexemes[t][len] = '\0';

    if (len > 5) {
        strcpy(message, "Number too long");
        tokens[t] = skipsym;
    } else {
        tokens[t] = numbersym;
    }
    t++;
    k--; // adjust
}

‚úÖ Corrected snippet for identifiers
else if (isalpha(info[k])) {
    int len = 0;
    memset(lexemes[t], 0, sizeof(lexemes[t]));
    while (isalnum(info[k]) && len < 11) {
        lexemes[t][len++] = info[k++];
    }
    lexemes[t][len] = '\0';

    if (len > 11) {
        strcpy(message, "Identifier too long");
        tokens[t] = skipsym;
    } else {
        tokens[t] = identsym;
    }
    t++;
    k--; // adjust
}


This will fix the ‚Äújunk characters‚Äù issue because:

Every token string is freshly initialized.

You‚Äôre not accidentally copying past the buffer with strncat.

Whitespace is skipped properly and never ends up in a token.

üëâ Do you want me to rewrite the whole switch loop cleanly with these fixes applied so you can drop it in directly?

You said:
I implemented those changes, and the weird characters are gone. But the spaces after the semicolon and begin are still there
ChatGPT said:

Got it üëç

The ‚Äúspaces‚Äù you‚Äôre still seeing after ; or begin aren‚Äôt actually being tokenized ‚Äî they‚Äôre just still sitting in your info buffer because of how you read and store the file contents:

Right now you do this:

while ((j = fgetc(inputFile)) != EOF && i < sizeof(info) - 1) {
    if ((char) j == ' ' || (char) j == '\t' || (char) j == '\n') {
        continue; // Skip whitespace
    }
    info[i++] = (char) j;
}


That looks fine, but here‚Äôs the subtle problem:

You‚Äôre skipping whitespace when you copy into info[], but not when you tokenize.

In your switch, anything that doesn‚Äôt match a known token falls into the default case, which still tries to copy info[k] into a token string ‚Äî that includes leftover invisible characters, carriage returns (\r from Windows files), or even null padding.

‚úÖ Fix #1: Filter whitespace + carriage returns during tokenization too

At the top of your for-loop over info[k], add:

if (info[k] == ' ' || info[k] == '\t' || info[k] == '\n' || info[k] == '\r') {
    continue;
}


That guarantees whitespace never reaches your token logic.

‚úÖ Fix #2: Trim lexeme strings before printing

Sometimes lexemes can accidentally pick up a trailing space. Add a helper:

void trim(char *s) {
    int len = strlen(s);
    while (len > 0 && isspace((unsigned char)s[len - 1])) {
        s[--len] = '\0';
    }
}


And just before printing:

trim(lexemes[t-1]);
printf("%-7s %-10d\n", lexemes[t-1], tokens[t-1]);

‚úÖ Fix #3: Handle Windows line endings

If your file was saved with Windows line endings (\r\n), then the \r sneaks in. That‚Äôs why you‚Äôre seeing ‚Äúghost spaces‚Äù after keywords. Filtering \r as shown in Fix #1 eliminates this.

So the minimal change that should solve your current issue is:

if (info[k] == ' ' || info[k] == '\t' || info[k] == '\n' || info[k] == '\r') {
    continue;
}


inside your tokenization loop.

üëâ Do you want me to patch your full switch loop with this change already integrated so you can just drop it in?

You said:
that first one did it, thank you
ChatGPT said:

Perfect üéâ glad that nailed it. The stray spaces were just those sneaky \r carriage returns hiding in your input. Filtering them out is the cleanest fix.

Do you want me to also help tighten up your lexer loop so keywords/identifiers/numbers are built more systematically (instead of all those manual case 'b': ... checks), or are you good with the current structure for now?
You said:
int len = 0;
    memset(lexemes[t], 0, sizeof(lexemes[t]));
    while (isdigit(info[k]) && len < 5) {
        lexemes[t][len++] = info[k++];
    }
    lexemes[t][len] = '\0';

    if (len > 5) {
        strcpy(message, "Number too long");
        tokens[t] = skipsym;
    } else {
        tokens[t] = numbersym;
    }
    t++;
    k--; // adjust
} theres one final problem with this snippet. When entering a number with length greater than 5, it needs to error and display the proper message. However, for input '123456' the code doesn't error, and displays the 3 token, how can I fix this?
ChatGPT said:

Ah, I see what‚Äôs happening üëç

Your loop is written like this:

while (isdigit(info[k]) && len < 5) {
    lexemes[t][len++] = info[k++];
}


That condition len < 5 means the loop stops before you ever copy the 6th digit. So "123456" only copies "12345" into lexemes[t], and then the if (len > 5) check never triggers (because len == 5).

‚úÖ Fix: Let the loop run until the number really ends, then check the length

Instead of limiting in the while, scan the whole number, then test its length:

int start = k;
while (isdigit(info[k])) {
    k++;
}
int len = k - start;

if (len > 5) {
    strncpy(lexemes[t], &info[start], 19); // copy safely
    lexemes[t][19] = '\0';
    strcpy(message, "Number too long");
    tokens[t] = skipsym;
} else {
    strncpy(lexemes[t], &info[start], len);
    lexemes[t][len] = '\0';
    tokens[t] = numbersym;
}
t++;
k--; // adjust for outer loop

Why this works

while (isdigit(info[k])) consumes the entire number.

len = k - start gives the actual digit count.

If it‚Äôs over 5, flag it as error.

Otherwise, copy it normally.

Now for input 123456, len == 6, so you‚Äôll correctly hit the error branch and print "Number too long".

üëâ Want me to also rewrite the identifier-handling part in the same clean style (instead of manually checking 'b', 'e', 'i', etc.) so it‚Äôs consistent and easier to extend?

You said:
if (isdigit(info[k])) {
    int len = 0;
    memset(lexemes[t], 0, sizeof(lexemes[t]));
    while (isdigit(info[k]) && len < 5) {
        lexemes[t][len++] = info[k++];
        len++;
    }
    lexemes[t][len] = '\0';

    if (len > 5) {
        strcpy(message, "Number too long");
        tokens[t] = skipsym;
    } else {
        tokens[t] = numbersym;
    }
    t++;
    k--; // adjust
} I got the same error, heres the same code snippet, but with an updated condition at the top
ChatGPT said:

I see the issue right away üö®

In your updated snippet you accidentally increment len twice per loop:

while (isdigit(info[k]) && len < 5) {
    lexemes[t][len++] = info[k++];
    len++;   // <-- this line is the problem
}


That extra len++ means for "123456" the counter goes out of sync:

1st digit: len = 1, then len++ makes it 2

2nd digit: len = 3

3rd digit: len = 5

then the condition len < 5 fails prematurely

so it never sees the 6th digit at all, and never triggers the error branch.

‚úÖ Correct version

Remove that second len++ entirely.
But also, don‚Äôt cut the loop off at len < 5 if you want to catch ‚Äútoo long‚Äù numbers. Instead, scan all digits then check length:

if (isdigit(info[k])) {
    int start = k;
    int len = 0;

    // Scan full number
    while (isdigit(info[k])) {
        k++;
        len++;
    }

    // Copy number into lexeme (truncate safely if huge)
    strncpy(lexemes[t], &info[start], len);
    lexemes[t][len] = '\0';

    if (len > 5) {
        strcpy(message, "Number too long");
        tokens[t] = skipsym;
    } else {
        tokens[t] = numbersym;
    }

    t++;
    k--; // adjust for outer loop increment
}

Why this works

while (isdigit(info[k])) eats the entire digit sequence.

len reflects the true length (123456 ‚Üí len == 6).

Error fires if len > 5.

No weird double increment.

üëâ Do you want me to also show the identifier case fixed in the same style (so it catches abcdefabcdef as "Identifier too long")? That way both number and identifier handling are consistent.

My prompt: How do I open and read a text file properly?

Github Copilot said: 

To open and read a text file in C, use the fopen, fgets or fscanf, and fclose functions. Here‚Äôs a simple example that reads and prints each line from input.txt:

#include <stdio.h>

int main() {
    FILE *file = fopen("input.txt", "r");
    if (file == NULL) {
        perror("Error opening file");
        return 1;
    }

    char line[256];
    while (fgets(line, sizeof(line), file)) {
        printf("%s", line);
    }

    fclose(file);
    return 0;
}

My prompt: Why is the while loop not reading the entire input.txt file?

Github Copilot said: 

The issue is with the condition in your while loop:
while (!fgets(info, sizeof(info), inputFile))
This loop only runs when fgets returns NULL (i.e., when it fails), so it never reads the file contents.

Fix:
Change the condition to run while fgets successfully reads a line:

while (fgets(info, sizeof(info), inputFile)) {
    printf("%s", info);
}

My prompt: Why is the while loop only storing the last line's information

Github Copilot said: 

The `info` array is overwritten on each iteration of the `while` loop, so after the loop ends, it only contains the last line read from the file. If you want to store all lines, you need to use a 2D array or dynamically allocate memory for each line.

**Example using a 2D array:**

```c
#include <stdio.h>
#include <string.h>

int main(int argc, char* argv[]) {
    FILE *inputFile = fopen(argv[1], "r");
    if (!inputFile) {
        printf("Error opening file.\n");
        return 1;
    }

    char lines[100][1000]; // Store up to 100 lines, each up to 999 chars
    int count = 0;
    while (fgets(lines[count], sizeof(lines[count]), inputFile) && count < 100) {
        count++;
    }

    // Print all lines
    for (int i = 0; i < count; i++) {
        printf("%s", lines[i]);
    }

    fclose(inputFile);
    return 0;
}
```

This way, each line is stored separately and not overwritten.

My prompt: What is causing the last for loop to not print any tokens?

Github Copilot said: 

The last `for` loop is not printing any tokens because the file pointer is at the end of the file after the first `while (fgets(...))` loop. When you try to read the file again with `fgetc(inputFile)`, it immediately returns `EOF`, so `info` remains mostly empty, and the tokenization logic does not process any real input.

**Fix:**  
After printing the file contents, you need to reset the file pointer to the beginning using `fseek(inputFile, 0, SEEK_SET);` before reading the file again.

**Example:**
```c
// After printing the file contents
fseek(inputFile, 0, SEEK_SET);
```

Add this line before the second loop that reads characters with `fgetc`. This will allow your tokenization logic to process the file content as intended.

My prompt: How do I make lexemes hold strings?

Github Copilot said: To make `lexemes` hold strings, ensure each entry is a character array (which you already have: `char lexemes[100][20];`).  
When storing a lexeme, use `strcpy` to copy the string into the array instead of assigning characters one by one.

**Example:**  
To store the string `"begin"` as a lexeme:
```c
#include <string.h>

// Store "begin" in lexemes[t]
strcpy(lexemes[t], "begin");
```

Use `strcpy(lexemes[t], "your_lexeme");` whenever you want to store a string lexeme.  
This will correctly store the entire string in the `lexemes` array.

My prompt: Can you modify the lex.c file's final for loop's switch case statement to add the token name to the lexeme array? Do not add the token name, add the entire name constructed by the characters read in the file. For example, if "begin" is read, do not add "beginsym", instead add "begin"

Github Copilot said: 
To store the full lexeme (e.g., "begin") in the `lexemes` array, use `strncpy` or `sprintf` to copy the entire matched string when a keyword or identifier is recognized.  
Currently, only the first character is set, and the rest are set manually.  
Below is a brief fix for the `begin` case (apply similarly to other keywords):

```c
// For "begin"
if (info[k+1] == 'e' && info[k+2] == 'g' && info[k+3] == 'i' && info[k+4] == 'n') {
    tokens[t] = beginsym;
    strncpy(lexemes[t], &info[k], 5); // Copy "begin"
    lexemes[t][5] = '\0';
    t++;
    k += 4;
}
```

For identifiers, numbers, and other keywords, use a loop or `strncpy` to copy the full lexeme as you recognize it.  
This ensures `lexemes[t]` contains the actual string from the file, not just the token name.

My prompt: Why does the program end in a runtime error?

Github Copilot said: 

The program ends in a runtime error (exit code -1073741819 / 0xC0000005) because of an **out-of-bounds array access** in the final for loop.  
Specifically, in the `default` case, you increment `t` before calling `strcpy(lexemes[t], (const char *) info[k]);`, so you write to an uninitialized or invalid index of `lexemes`.

Also, `(const char *) info[k]` is incorrect: `info[k]` is a `char`, not a string, so this does not copy a valid string and can cause undefined behavior.

**How to fix:**
- Only increment `t` after all assignments to `lexemes[t]` and `tokens[t]`.
- To copy a single character as a string, use:
  ```c
  lexemes[t][0] = info[k];
  lexemes[t][1] = '\0';
  ```
- Make sure all `strcpy`/`strncpy` calls use valid, null-terminated strings.

**Summary:**  
The runtime error is due to writing outside the bounds of the `lexemes` array and using invalid string operations.

My prompt: How do I print the lexemes alongside the token number properly?

Github Copilot said: 

To print lexemes with their token numbers correctly, print each `lexemes[t]` and `tokens[t]` **immediately after** you assign them, and **before** incrementing `t`.  
For single-character tokens, this is straightforward. For multi-character tokens (like keywords), ensure you copy the full lexeme string before printing.

**Example fix:**

```c
// After setting lexeme and token, print, then increment t
strcpy(lexemes[t], "+");
tokens[t] = plussym;
printf("%s\t%d\n", lexemes[t], tokens[t]);
t++;
```

**For multi-character lexemes:**

```c
strncpy(lexemes[t], &info[k], 5); // e.g., for "begin"
lexemes[t][5] = '\0';
tokens[t] = beginsym;
printf("%s\t%d\n", lexemes[t], tokens[t]);
t++;
k += 4; // Skip the rest of the keyword
```

**Summary:**  
- Always print `lexemes[t]` and `tokens[t]` right after setting them, before incrementing `t`.
- For single characters, set `lexemes[t][0] = info[k]; lexemes[t][1] = '\0';` if needed.
- For multi-character lexemes, use `strncpy` and null-terminate.

This ensures each lexeme is printed with its correct token number.

My prompt: How do I make the check for integer values as tokens more efficient and easier to read than the current 5 nested if statements?

Github Copilot said: 

You can simplify the integer token check by using a loop to collect consecutive digits, then check the length for errors. This is more readable and scalable.

**Example:**

```c
// Scan for a number token
if (isdigit(info[k])) {
    int start = k;
    int len = 0;
    while (isdigit(info[k]) && len < 6) { // Allow up to 6 to check for error
        k++;
        len++;
    }
    if (len > 5) {
        printf("Error: Number too long\n");
        // Skip the rest of the digits
        while (isdigit(info[k])) k++;
        k--; // Adjust for the outer loop increment
    } else {
        strncpy(lexemes[t], &info[start], len);
        lexemes[t][len] = '\0';
        tokens[t] = numbersym;
        t++;
        k--; // Adjust for the outer loop increment
    }
}
```

**Explanation:**  
- Use a loop to count digits and build the lexeme.
- If more than 5 digits, print an error and skip the number.
- Otherwise, copy the digits as the lexeme and set the token.

My prompt: How do I handle comments in this lexical analyzer without erasing the entire file's tokens?

Github Copilot said: To handle comments in your lexical analyzer without affecting the rest of the tokens, simply **skip over comment sections** during tokenization. For example, if comments are delimited by `//` (single-line) or `/* ... */` (multi-line), detect the start of a comment and advance the index until the comment ends, ignoring all characters in between.

**Example for single-line comments (`//`):**

```c
if (info[k] == '/' && info[k+1] == '/') {
    // Skip until end of line or end of file
    k += 2;
    while (info[k] != '\n' && info[k] != '\0') {
        k++;
    }
    // k will be incremented by the main loop
    continue;
}
```

**Example for multi-line comments (`/* ... */`):**

```c
if (info[k] == '/' && info[k+1] == '*') {
    k += 2;
    while (!(info[k] == '*' && info[k+1] == '/') && info[k] != '\0') {
        k++;
    }
    if (info[k] != '\0') k += 2; // Skip past '*/'
    continue;
}
```

**Summary:**  
- Detect comment start.
- Skip all characters until the comment ends.
- Do not generate tokens for comment content.
- Resume normal tokenization after the comment.  
This way, comments are ignored and do not interfere with the rest of the file's tokens.

My prompt: What if I need to also tokenize the comment delimiters (e.g. //, /*, and */)?

Github Copilot said: 

To tokenize comment delimiters, treat them as special tokens in your analyzer. When you detect `//`, `/*`, or `*/`, add them to your `lexemes` and `tokens` arrays before skipping the comment content.

**Example logic:**
- When you see `//`, add it as a lexeme, assign a token (e.g., `commentsym`), then skip to the end of the line.
- For `/*`, add it as a lexeme, assign a token, then skip until you find `*/`, which you also add as a lexeme and token.

**Sample code:**
```c
if (info[k] == '/' && info[k+1] == '/') {
    strcpy(lexemes[t], "//");
    tokens[t] = commentsym; // Define commentsym as needed
    printf("%s\t%d\n", lexemes[t], tokens[t]);
    t++;
    k += 2;
    while (info[k] != '\n' && info[k] != '\0') k++;
    continue;
}
if (info[k] == '/' && info[k+1] == '*') {
    strcpy(lexemes[t], "/*");
    tokens[t] = commentsym;
    printf("%s\t%d\n", lexemes[t], tokens[t]);
    t++;
    k += 2;
    while (!(info[k] == '*' && info[k+1] == '/') && info[k] != '\0') k++;
    if (info[k] == '*' && info[k+1] == '/') {
        strcpy(lexemes[t], "*/");
        tokens[t] = commentsym;
        printf("%s\t%d\n", lexemes[t], tokens[t]);
        t++;
        k += 2;
    }
    continue;
}
```
**Summary:**  
- Add comment delimiters as lexemes and assign a token.
- Skip the comment content as before.  
This way, the delimiters are tokenized, but the comment body is ignored.

My prompt: How would I modify the current comment skipping logic to include the comment delimiters as characters in the tokens array?

Github Copilot said: To include comment delimiters (`//`, `/*`, `*/`) as tokens, update your logic so that when you detect a comment delimiter, you:

1. Add the delimiter to `lexemes[t]` and set the appropriate token type (e.g., `commentsym` or a new token).
2. Print or store the delimiter token.
3. Skip the comment content as before.
4. For multi-line comments, also add `*/` as a token when you reach the end.

**Example modification for the main tokenization loop:**

```c
// Inside your main tokenization loop
if (info[k] == '/' && info[k+1] == '/') {
    strcpy(lexemes[t], "//");
    tokens[t] = skipsym; // Or define a commentsym
    printf("%-7s %-10d\n", lexemes[t], tokens[t]);
    t++;
    k += 2;
    while (info[k] != '\n' && info[k] != '\0') k++;
    continue;
}
if (info[k] == '/' && info[k+1] == '*') {
    strcpy(lexemes[t], "/*");
    tokens[t] = skipsym; // Or define a commentsym
    printf("%-7s %-10d\n", lexemes[t], tokens[t]);
    t++;
    k += 2;
    while (!(info[k] == '*' && info[k+1] == '/') && info[k] != '\0') k++;
    if (info[k] == '*' && info[k+1] == '/') {
        strcpy(lexemes[t], "*/");
        tokens[t] = skipsym; // Or define a commentsym
        printf("%-7s %-10d\n", lexemes[t], tokens[t]);
        t++;
        k += 2;
    }
    continue;
}
```

**Summary:**  
- Add the delimiter as a token before skipping the comment.
- For `/* ... */`, add both `/*` and `*/` as tokens.
- Use a dedicated token type if desired (e.g., `commentsym`).

My prompt: Why is the /* comment delimiter only having the * tokenized and the / ignored?

Github Copilot said: This happens because in your file reading loop, when you detect `/*`, you add `/` and `*` as separate characters to the `info` array:

```c
info[i++] = '/';
info[i++] = (char) j; // j is '*'
```

But in your tokenization loop, you only check for `info[k] == '/' && info[k+1] == '*'` to form the `/*` token. However, after skipping the comment, you do not ensure that both `/` and `*` are still together in the `info` array. Also, your reading loop adds `/` and `*` separately, so the tokenization loop may not always see them as a pair.

**Solution:**  
Do not add `/` and `*` to the `info` array in the reading loop.  
Instead, only skip the comment content in the reading loop, and let the tokenization loop handle the detection and tokenization of `/*` by looking for adjacent `/` and `*` in `info`.

**Summary:**  
- Remove `info[i++] = '/';` and `info[i++] = (char) j;` from the reading loop for comments.
- Only skip comment content in the reading loop.
- Tokenize `/*` in the tokenization loop by checking for adjacent `/` and `*` in `info`.

This will ensure `/*` is tokenized as a single delimiter.
